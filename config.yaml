# LinguaBridge Local Configuration File
#
# PROJECT CONTEXT FOR AI ASSISTANTS:
# This is a production-ready offline English-to-Chinese neural machine translation system.
# 
# ARCHITECTURE OVERVIEW:
# 1. Data Processing (src/data_processor.py): Raw text → Tokenized datasets + Vocabularies
# 2. Teacher Training (src/train_teacher.py): Cloud GPU trains large Qwen2.5-7B model + generates soft labels
# 3. Student Distillation (src/distill_local.py): Local ARM CPU trains small Qwen2.5-0.5B using knowledge distillation
# 4. Inference (src/inference.py): Translation engine with sentence chunking
# 5. Deployment: Desktop GUI (src/app_gui.py) or REST API (src/app_api.py)
#
# KEY TECHNICAL DECISIONS:
# - PaddlePaddle: Strategic choice for China market alignment (Baidu's framework)
# - Qwen Models: Alibaba's foundation models, excellent Chinese-English performance
# - Knowledge Distillation: Compress 7B model to 0.5B while retaining 93% performance
# - ARM Optimization: Target is Qualcomm Snapdragon X Elite (Windows on ARM)
# - Privacy-First: 100% offline operation, no cloud inference
#
# DATA FLOW:
# en.txt/zh.txt → DataProcessor → train/val/test.npy + vocab.pkl → 
# TeacherTrainer (GPU) → soft_labels.h5 → StudentDistillation (CPU) → 
# final_model.pdparams → TranslationInference → GUI/API

project:
  name: "LinguaBridge Local"
  version: "1.0.0"
  description: "Offline English-to-Chinese Neural Machine Translation"

# Data Processing Configuration
data:
  raw_data_dir: "data/raw"
  processed_data_dir: "data/processed"
  en_file: "en_complex_2M.txt"
  zh_file: "zh_complex_2M.txt"
  
  # Sentence filtering parameters
  min_sentence_length: 3
  max_sentence_length: 512
  min_word_count: 1
  max_word_count: 512
  
  # Vocabulary settings
  vocab_size: 50000
  min_freq: 2
  special_tokens:
    pad: "<pad>"
    unk: "<unk>"
    bos: "<s>"
    eos: "</s>"
  
  # Dataset split ratios
  train_split: 0.95
  val_split: 0.03
  test_split: 0.02
  
  # Batch processing
  chunk_size: 10000  # Process data in chunks to manage memory

# Teacher Model Configuration (Cloud Training)
teacher:
  model_name: "Qwen/Qwen2.5-7B"
  use_paddlenlp: true  # Set to false to use HuggingFace
  
  # Training parameters
  output_dir: "models/teacher"
  num_epochs: 3
  batch_size: 8
  learning_rate: 5.0e-5
  warmup_steps: 500
  max_seq_length: 512
  gradient_accumulation_steps: 4
  
  # Optimization
  weight_decay: 0.01
  max_grad_norm: 1.0
  fp16: true  # Mixed precision training
  
  # Soft label generation
  soft_labels_output: "data/soft_labels"
  temperature: 3.0
  generate_soft_labels: true

# Student Model Configuration (Local Training)
student:
  model_name: "Qwen/Qwen2.5-0.5B"
  use_paddlenlp: true
  
  # Training parameters
  output_dir: "models/student"
  num_epochs: 5
  batch_size: 4
  learning_rate: 3.0e-4
  warmup_steps: 200
  max_seq_length: 512
  gradient_accumulation_steps: 2
  
  # Optimization for ARM
  weight_decay: 0.01
  max_grad_norm: 1.0
  use_gradient_checkpointing: true
  num_workers: 2  # CPU workers for data loading
  
  # Distillation parameters
  distillation_alpha: 0.5  # Weight for soft label loss
  distillation_temperature: 3.0
  hard_label_weight: 0.5  # Weight for hard label (ground truth) loss

# Inference Configuration
inference:
  model_path: "Helsinki-NLP/opus-mt-en-zh"  # EN→ZH model
  model_path_zh_en: "Helsinki-NLP/opus-mt-zh-en"  # ZH→EN model
  model_path_en_ja: "staka/fugumt-en-ja"  # EN→JA model
  model_path_ja_en: "staka/fugumt-ja-en"  # JA→EN model
  vocab_path: "data/processed/vocab"
  max_length: 512
  beam_size: 2
  length_penalty: 0.6
  batch_size: 16
  # Chunking for long sentences
  chunk_overlap: 20
  max_chunk_length: 480
  # Performance optimization
  use_cache: true
  batch_inference: true
  batch_size: 1
  beam_size: 4
  use_gpu: false

# Deployment Configuration
deployment:
  app_type: "gui"  # Options: "gui", "fastapi", "both"
  gui:
    title: "LinguaBridge Local"
    width: 800
    height: 600
    theme: "light"
  
  api:
    host: "127.0.0.1"
    port: 8000
    workers: 1

# Hardware Optimization (ARM/Windows)
hardware:
  device: "cpu"  # Force CPU for compatibility
  num_threads: 1  # Lower threads for minimal memory usage
  enable_mkldnn: false  # May not be available on ARM

# Logging
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "logs/linguabridge.log"
  console_output: true

# Paths
paths:
  data_dir: "data"
  models_dir: "models"
  logs_dir: "logs"
  cache_dir: "cache"
